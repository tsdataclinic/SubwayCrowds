{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, logging\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import turnstile\n",
    "import gtfs\n",
    "import heuristics\n",
    "\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)\n",
    "\n",
    "from gcs_utils import gcs_util\n",
    "gcs = gcs_util(bucket_path='mta_crowding_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading pre-requisite files\n",
    "stop_order_merged = pd.read_csv('data/stops.csv')\n",
    "crosswalk = pd.read_csv('data/Master_crosswalk.csv')\n",
    "station_to_station = pd.read_csv('data/station_to_station.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining date range for estimation\n",
    "LAST_TURNSTILE_DATE = datetime(year=2020,month=10,day=18)\n",
    "DAYS_RANGE = 2\n",
    "\n",
    "dates = [LAST_TURNSTILE_DATE - timedelta(days=i) for i in range(1,DAYS_RANGE +1)]\n",
    "keep_dates = [re.sub('-','',str(d.date())) for d in dates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## proceesing real-time GTFS data\n",
    "df, dates = gtfs.get_schedule(LAST_TURNSTILE_DATE,DAYS_RANGE)\n",
    "clean_df = gtfs.process_schedule(df, min(dates), max(dates), stop_order_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939     61\n",
       "944     61\n",
       "1077    61\n",
       "1240    61\n",
       "938     61\n",
       "        ..\n",
       "9384     2\n",
       "9548     2\n",
       "9128     2\n",
       "9804     2\n",
       "9999     2\n",
       "Name: uid, Length: 14257, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_static_schedule.uid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## proceesing static GTFS data\n",
    "static_schedule = pd.read_csv('data/google_transit/stop_times.txt')\n",
    "trips = pd.read_csv('data/google_transit/trips.txt')\n",
    "stops = pd.read_csv('data/google_transit/stops.txt')\n",
    "static_schedule = static_schedule.merge(trips,on='trip_id').merge(stops,on='stop_id')\n",
    "\n",
    "last_year_start = min(dates) - timedelta(weeks=52)\n",
    "last_year_end = max(dates) - timedelta(weeks=52)\n",
    "\n",
    "clean_static_schedule = gtfs.process_static_schedule(static_schedule,last_year_start, last_year_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-26 05:14:25,114 - root - INFO - Downloading turnstile data\n",
      "2020-10-26 05:14:27,502 - root - INFO - Cleaning turnstile data\n",
      "2020-10-26 05:14:31,216 - root - INFO - Start interpolating turnstile data\n",
      "2020-10-26 05:15:04,086 - root - INFO - Finish interpolating\n",
      "2020-10-26 05:15:07,891 - root - INFO - Finish concatenating the result\n",
      "2020-10-26 05:15:10,658 - root - INFO - Downloading turnstile data\n",
      "2020-10-26 05:15:12,566 - root - INFO - Cleaning turnstile data\n",
      "2020-10-26 05:15:16,345 - root - INFO - Start interpolating turnstile data\n",
      "2020-10-26 05:15:47,420 - root - INFO - Finish interpolating\n",
      "2020-10-26 05:15:51,587 - root - INFO - Finish concatenating the result\n",
      "2020-10-26 05:15:55,144 - root - INFO - Downloading turnstile data\n",
      "2020-10-26 05:15:57,001 - root - INFO - Cleaning turnstile data\n",
      "2020-10-26 05:16:02,074 - root - INFO - Start interpolating turnstile data\n",
      "2020-10-26 05:16:25,982 - root - INFO - Finish interpolating\n",
      "2020-10-26 05:16:28,584 - root - INFO - Finish concatenating the result\n"
     ]
    }
   ],
   "source": [
    "## Processing Turnstile data\n",
    "\n",
    "## Current\n",
    "turnstile_data_raw = turnstile._process_raw_data(turnstile.download_turnstile_data(start_date=min(dates), end_date=max(dates)), group_by=['STATION','LINENAME','UNIT'])\n",
    "turnstile_data_raw_imputed = turnstile.pre_interpolation_fix(turnstile_data_raw)\n",
    "turnstile_data_raw_imputed = turnstile_data_raw_imputed.set_index('datetime')\n",
    "turnstile_data = turnstile._interpolate(turnstile_data_raw_imputed, group_by=['STATION','LINENAME','UNIT'],  frequency='1T')\n",
    "turnstile_data = turnstile_data[turnstile_data.index.to_series().between(min(dates), max(dates))] .drop(columns=[\"entry_diffs\", \"exit_diffs\"])\n",
    "turnstile_data_cleaned = turnstile.consolidate_turnstile_data(turnstile_data)\n",
    "\n",
    "## Last Month\n",
    "last_month_start = min(dates) - timedelta(weeks=4)\n",
    "last_month_end = max(dates) - timedelta(weeks=4)\n",
    "turnstile_data_raw = turnstile._process_raw_data(turnstile.download_turnstile_data(start_date=last_month_start, end_date=last_month_end), group_by=['STATION','LINENAME','UNIT'])\n",
    "turnstile_data_raw_imputed = turnstile.pre_interpolation_fix(turnstile_data_raw)\n",
    "turnstile_data_raw_imputed = turnstile_data_raw_imputed.set_index('datetime')\n",
    "last_month_turnstile_data = turnstile._interpolate(turnstile_data_raw_imputed, group_by=['STATION','LINENAME','UNIT'],  frequency='1T')\n",
    "last_month_turnstile_data = last_month_turnstile_data[last_month_turnstile_data.index.to_series().between(last_month_start, last_month_end)] .drop(columns=[\"entry_diffs\", \"exit_diffs\"])\n",
    "last_month_turnstile_data = last_month_turnstile_data.reset_index()\n",
    "last_month_turnstile_data['datetime'] = last_month_turnstile_data.datetime + timedelta(weeks=4)\n",
    "last_month_turnstile_data = last_month_turnstile_data.set_index('datetime')\n",
    "last_month_turnstile_data_cleaned = turnstile.consolidate_turnstile_data(last_month_turnstile_data)\n",
    "\n",
    "## Last Year\n",
    "last_year_start = min(dates) - timedelta(weeks=52)\n",
    "last_year_end = max(dates) - timedelta(weeks=52)\n",
    "turnstile_data_raw = turnstile._process_raw_data(turnstile.download_turnstile_data(start_date=last_year_start, end_date=last_year_end), group_by=['STATION','LINENAME','UNIT'])\n",
    "turnstile_data_raw_imputed = turnstile.pre_interpolation_fix(turnstile_data_raw)\n",
    "turnstile_data_raw_imputed = turnstile_data_raw_imputed.set_index('datetime')\n",
    "last_year_turnstile_data = turnstile._interpolate(turnstile_data_raw_imputed, group_by=['STATION','LINENAME','UNIT'],  frequency='1T')\n",
    "last_year_turnstile_data = last_year_turnstile_data[last_year_turnstile_data.index.to_series().between(last_year_start, last_year_end)] .drop(columns=[\"entry_diffs\", \"exit_diffs\"])\n",
    "last_year_turnstile_data_cleaned = turnstile.consolidate_turnstile_data(last_year_turnstile_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk = crosswalk[~(crosswalk.turnstile_station_name == '14TH STREET')]\n",
    "\n",
    "schedule = heuristics.get_schedule_with_weights(turnstile_data_cleaned,clean_df,stop_order_merged)\n",
    "schedule_last_month = heuristics.get_schedule_with_weights(last_month_turnstile_data_cleaned,clean_df,stop_order_merged)\n",
    "schedule_last_year = heuristics.get_schedule_with_weights(last_year_turnstile_data_cleaned,clean_static_schedule,stop_order_merged)\n",
    "\n",
    "df_merge = heuristics.merge_turnstile_schedule(turnstile_data_cleaned,crosswalk, schedule)\n",
    "last_month_df_merge = heuristics.merge_turnstile_schedule(last_month_turnstile_data_cleaned,crosswalk, schedule_last_month)\n",
    "last_year_df_merge = heuristics.merge_turnstile_schedule(last_year_turnstile_data_cleaned,crosswalk, schedule_last_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>datetime</th>\n",
       "      <th>estimated_entries</th>\n",
       "      <th>estimated_exits</th>\n",
       "      <th>total_entries</th>\n",
       "      <th>total_exits</th>\n",
       "      <th>modified_linename</th>\n",
       "      <th>hour_x</th>\n",
       "      <th>gtfs_station_name</th>\n",
       "      <th>...</th>\n",
       "      <th>uid</th>\n",
       "      <th>legitimate_trunc</th>\n",
       "      <th>max_trip_length</th>\n",
       "      <th>trip_length</th>\n",
       "      <th>pct_max</th>\n",
       "      <th>time</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>hour_y</th>\n",
       "      <th>entry_weight</th>\n",
       "      <th>exit_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>2020-10-16 00:00:00</td>\n",
       "      <td>1.701719</td>\n",
       "      <td>1.714170</td>\n",
       "      <td>1.701719</td>\n",
       "      <td>1.714170</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Av</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>2020-10-16 00:01:00</td>\n",
       "      <td>1.687302</td>\n",
       "      <td>1.702138</td>\n",
       "      <td>3.389022</td>\n",
       "      <td>3.416309</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Av</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>2020-10-16 00:02:00</td>\n",
       "      <td>1.672885</td>\n",
       "      <td>1.690107</td>\n",
       "      <td>5.061907</td>\n",
       "      <td>5.106415</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Av</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>2020-10-16 00:03:00</td>\n",
       "      <td>1.658468</td>\n",
       "      <td>1.678075</td>\n",
       "      <td>6.720374</td>\n",
       "      <td>6.784490</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Av</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 AV</td>\n",
       "      <td>L</td>\n",
       "      <td>2020-10-16 00:04:00</td>\n",
       "      <td>1.644051</td>\n",
       "      <td>1.666043</td>\n",
       "      <td>8.364425</td>\n",
       "      <td>8.450534</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>1 Av</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATION LINENAME            datetime  estimated_entries  estimated_exits  \\\n",
       "0    1 AV        L 2020-10-16 00:00:00           1.701719         1.714170   \n",
       "1    1 AV        L 2020-10-16 00:01:00           1.687302         1.702138   \n",
       "2    1 AV        L 2020-10-16 00:02:00           1.672885         1.690107   \n",
       "3    1 AV        L 2020-10-16 00:03:00           1.658468         1.678075   \n",
       "4    1 AV        L 2020-10-16 00:04:00           1.644051         1.666043   \n",
       "\n",
       "   total_entries  total_exits modified_linename  hour_x gtfs_station_name  \\\n",
       "0       1.701719     1.714170                 L       0              1 Av   \n",
       "1       3.389022     3.416309                 L       0              1 Av   \n",
       "2       5.061907     5.106415                 L       0              1 Av   \n",
       "3       6.720374     6.784490                 L       0              1 Av   \n",
       "4       8.364425     8.450534                 L       0              1 Av   \n",
       "\n",
       "   ... uid legitimate_trunc  max_trip_length  trip_length pct_max time  \\\n",
       "0  ... NaN              NaN              NaN          NaN     NaN  NaT   \n",
       "1  ... NaN              NaN              NaN          NaN     NaN  NaT   \n",
       "2  ... NaN              NaN              NaN          NaN     NaN  NaT   \n",
       "3  ... NaN              NaN              NaN          NaN     NaN  NaT   \n",
       "4  ... NaN              NaN              NaN          NaN     NaN  NaT   \n",
       "\n",
       "  direction_id hour_y entry_weight exit_weight  \n",
       "0          NaN    NaN          NaN         NaN  \n",
       "1          NaN    NaN          NaN         NaN  \n",
       "2          NaN    NaN          NaN         NaN  \n",
       "3          NaN    NaN          NaN         NaN  \n",
       "4          NaN    NaN          NaN         NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-26 05:19:03,294 - root - INFO - Starting\n",
      "2020-10-26 05:19:06,507 - root - INFO - Getting people waiting at stations\n",
      "2020-10-26 05:19:45,358 - root - INFO - Getting crowd per train\n",
      "2020-10-26 05:20:42,618 - root - INFO - Finishing\n",
      "2020-10-26 05:20:42,620 - root - INFO - Starting\n",
      "2020-10-26 05:20:44,788 - root - INFO - Getting people waiting at stations\n",
      "2020-10-26 05:21:23,780 - root - INFO - Getting crowd per train\n",
      "2020-10-26 05:22:38,438 - root - INFO - Finishing\n",
      "2020-10-26 05:22:38,440 - root - INFO - Starting\n",
      "2020-10-26 05:22:42,892 - root - INFO - Getting people waiting at stations\n",
      "2020-10-26 05:23:30,142 - root - INFO - Getting crowd per train\n",
      "2020-10-26 05:24:52,171 - root - INFO - Finishing\n"
     ]
    }
   ],
   "source": [
    "## Crowd estimation\n",
    "crowd_by_station_line = heuristics.get_crowd_by_station_line(df_merge,entry_exit_ratio=1.25)\n",
    "last_month_crowd_by_station_line = heuristics.get_crowd_by_station_line(last_month_df_merge,entry_exit_ratio=1.25)\n",
    "last_year_crowd_by_station_line = heuristics.get_crowd_by_station_line(last_year_df_merge,entry_exit_ratio=1.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregating estimates by hour and weekday/weekend\n",
    "station_to_station['from'] = [re.sub(r'N$|S$','',x) for x in station_to_station['from']]\n",
    "station_to_station['to'] = [re.sub(r'N$|S$','',x) for x in station_to_station['to']]\n",
    "clean_stop_routes = station_to_station[['from','line']].rename(columns={'from':'stop_id'})\n",
    "clean_stop_routes = clean_stop_routes.append(station_to_station[['to','line']].rename(columns={'to':'stop_id'}))\n",
    "clean_stop_routes = clean_stop_routes.drop_duplicates()\n",
    "clean_stop_routes = clean_stop_routes[~clean_stop_routes.line.isin(['H','SI'])]\n",
    "clean_stop_routes['route_stop'] = clean_stop_routes['line'] + '_' + clean_stop_routes['stop_id']\n",
    "\n",
    "current_avg, current_avg_split = heuristics.get_hourly_averages(crowd_by_station_line, clean_stop_routes)\n",
    "last_month_avg, last_month_avg_split = heuristics.get_hourly_averages(last_month_crowd_by_station_line, clean_stop_routes)\n",
    "last_year_avg, last_year_avg_split = heuristics.get_hourly_averages(last_year_crowd_by_station_line, clean_stop_routes)\n",
    "\n",
    "current_avg.rename(columns={'crowd':'current_crowd'}, inplace=True)\n",
    "last_month_avg.rename(columns={'crowd':'last_month_crowd'}, inplace=True)\n",
    "last_year_avg.rename(columns={'crowd':'last_year_crowd'}, inplace=True)\n",
    "\n",
    "hourly_average_estimates = current_avg.merge(last_month_avg,on=['STATION','route_id','hour'])\n",
    "hourly_average_estimates = hourly_average_estimates.merge(last_year_avg,on=['STATION','route_id','hour'])\n",
    "\n",
    "current_avg_split.rename(columns={'crowd':'current_crowd'}, inplace=True)\n",
    "last_month_avg_split.rename(columns={'crowd':'last_month_crowd'}, inplace=True)\n",
    "last_year_avg_split.rename(columns={'crowd':'last_year_crowd'}, inplace=True)\n",
    "\n",
    "hourly_average_estimates_split = current_avg_split.merge(last_month_avg_split,on=['STATION','route_id','hour','direction_id','weekday'])\n",
    "hourly_average_estimates_split = hourly_average_estimates_split.merge(last_year_avg_split,on=['STATION','route_id','hour','direction_id','weekday'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_average_estimates_split.to_csv('../public/crowding_by_weekday_direction.csv',index=False)\n",
    "\n",
    "\n",
    "timestr = min(dates).strftime(\"%Y%m%d\")\n",
    "timesen = max(dates).strftime(\"%Y%m%d\")\n",
    "test_time = open('../public/timestamp.txt', 'w')\n",
    "test_time.write(timestr+'-'+timesen)\n",
    "test_time.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mta)",
   "language": "python",
   "name": "mta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
